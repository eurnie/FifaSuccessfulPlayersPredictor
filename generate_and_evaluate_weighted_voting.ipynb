{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and evaluate weighted voting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, mean_squared_error as mse\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PU_Learning import *\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "data = pd.read_csv('clean_data/players_17_clean_train.csv')\n",
    "train_x = data.iloc[:, :-1].values\n",
    "train_y = data.iloc[:, -1].values\n",
    "s = data.iloc[:, -1].values\n",
    "c = Counter(s)[1]/Counter(train_y)[1]\n",
    "\n",
    "# import test data \n",
    "data = pd.read_csv('clean_data/players_17_clean_test.csv')\n",
    "test_x = data.iloc[:, :-1].values\n",
    "test_y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-DNFII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of a certain score for a certain feature\n",
    "def frequency(feature, score, collection, deviation):\n",
    "    count = 0\n",
    "    for element in collection:\n",
    "        if (element[feature] > score - deviation) and (element[feature] < score + deviation):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a numpy array that holds all the elements of a that are not in b\n",
    "def setdiff_nd_positivenums(a, b):\n",
    "    s = np.maximum(a.max(0)+1,b.max(0)+1)\n",
    "    return a[~np.isin(a.dot(s),b.dot(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm improved 1-DNF (1-DNFII)\n",
    "def dnf(train_x, train_y, deviation, parameter_lambda):\n",
    "    num_rows, num_cols = train_x.shape\n",
    "    \n",
    "    # PF = positive feature set\n",
    "    PF = np.zeros(shape=(0, 2))\n",
    "    \n",
    "    # RN = reliable negatives\n",
    "    RN = np.zeros(shape=(0, num_cols))\n",
    "    RN_y = np.array([])\n",
    "    \n",
    "    # U = unlabeled\n",
    "    U = np.zeros(shape=(0, num_cols))\n",
    "    U_y = np.array([])\n",
    "    \n",
    "    # P = positive\n",
    "    P = np.zeros(shape=(0, num_cols))\n",
    "    P_y = np.array([])\n",
    "    \n",
    "    # construct P, U and RN\n",
    "    # at this moment: RN = U\n",
    "    for i in range(0, len(train_y)-1):\n",
    "        if (train_y[i] == 1):\n",
    "            P = np.vstack([P, train_x[i]])\n",
    "            P_y = np.append(P_y, train_y[i])\n",
    "        else:\n",
    "            U = np.vstack([U, train_x[i]])\n",
    "            U_y = np.append(U_y, train_y[i])\n",
    "            RN = np.vstack([RN, train_x[i]])\n",
    "            RN_y = np.append(RN_y, train_y[i])\n",
    "            \n",
    "    print(\"1-DNFII: RN is initialized\")\n",
    "\n",
    "    # construct PF\n",
    "    for i in range(0, num_cols-1):\n",
    "        for j in range(0, num_rows-1):\n",
    "            symbol = train_x[j][i]\n",
    "            if (not [i, symbol] in PF):\n",
    "                constraint_1 = frequency(i, symbol, P, deviation) / len(P)\n",
    "                constraint_2 = frequency(i, symbol, U, deviation) / len(U)\n",
    "                if (constraint_1 > constraint_2) and (constraint_1 > parameter_lambda):\n",
    "                    new = [i, symbol]\n",
    "                    PF = np.vstack([PF, new])\n",
    "                \n",
    "    print(\"1-DNFII: PF is constructed\")\n",
    "              \n",
    "    # construct list with indices of elements to remove from RN\n",
    "    # (based on PF)\n",
    "    index = []        \n",
    "    for i in range(0, len(RN)-1):\n",
    "        for constraint in PF:\n",
    "            element = RN[i]\n",
    "            if element[int(constraint[0])] == constraint[1]:\n",
    "                index.append(i)\n",
    "              \n",
    "    RN = np.delete(RN, index, 0)\n",
    "    RN_y = np.delete(RN_y, index, 0)\n",
    "                \n",
    "    print(\"1-DNFII: RN was finalized\")\n",
    "    \n",
    "    return P, P_y, U, U_y, RN, RN_y, PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation indicates whether two feature values are considered the same\n",
    "# if deviation = 0, the two feature values need to be exactly the same\n",
    "# if deviation = 1, feature value one need to be equal to feature value two - 1\n",
    "#                   OR feature value one need to be equal to feature value two + 1\n",
    "#                   OR the two feature values are exactly the same\n",
    "# parameter_lambda = the parameter lambda used in 1-DNFII\n",
    "def weighted_voting(train_x, train_y, deviation, parameter_lambda):\n",
    "    P, P_y, U, U_y, RN, RN_y, PF = dnf(train_x, train_y, deviation, parameter_lambda)\n",
    "    FinalWVClassifier = []\n",
    "    FinalWVClassifier_weights = []\n",
    "\n",
    "    # shuffle rows of P and then delete the first 10%\n",
    "    P = np.insert(P, len(P[0]), P_y, axis=1)\n",
    "    np.random.shuffle(P)\n",
    "    PP = P[:round(len(P)/10),:]\n",
    "    PP_y = PP[:, -1]\n",
    "    PP = np.delete(PP, -1, 1)\n",
    "    index = [x for x in range(0, round(len(P)/10))]\n",
    "    P = np.delete(P, index, 0)\n",
    "    P_y = P[:, -1]\n",
    "    P = np.delete(P, -1, 1)\n",
    "\n",
    "    PON = np.vstack([P, RN])\n",
    "    PON_y = np.append(P_y, RN_y)\n",
    "\n",
    "    RN = np.insert(RN, len(RN[0]), RN_y, axis=1)\n",
    "\n",
    "    U = np.insert(U, len(U[0]), U_y, axis=1)\n",
    "    U = setdiff_nd_positivenums(U, RN)\n",
    "    U_y = U[:, -1]\n",
    "    U = np.delete(U, -1, 1)\n",
    "\n",
    "    allPrecision = 0\n",
    "\n",
    "    last_U = 0\n",
    "\n",
    "    while (True):\n",
    "        if (len(U) == 0):\n",
    "            break\n",
    "\n",
    "        # create a new SVM\n",
    "        new_clf = make_pipeline(StandardScaler(), svm.SVC(gamma='auto'))\n",
    "\n",
    "        # round elements of PON_y to their nearest integer\n",
    "        PON_y = np.rint(PON_y)\n",
    "\n",
    "        # train the new SVM\n",
    "        new_clf.fit(np.copy(PON), np.copy(PON_y))\n",
    "\n",
    "        # predict the labels of the class U\n",
    "        NEG = new_clf.predict(np.copy(U))\n",
    "\n",
    "        # predict the labels of the class PP\n",
    "        predictions = new_clf.predict(np.copy(PP))\n",
    "\n",
    "        # calculate the precision of PP on the trained SVM\n",
    "        #precision = len(predictions[predictions == 1]) / len(predictions)\n",
    "        precision = f1_score(np.ones(len(predictions)), predictions)\n",
    "        allPrecision += precision\n",
    "\n",
    "        # initialize list with indexes that will be removed from U\n",
    "        index = []\n",
    "\n",
    "        # check which elements can be removed from U\n",
    "        for i in range(0, len(NEG)):\n",
    "            if (NEG[i] == 0):\n",
    "                index.append(i)\n",
    "                PON = np.vstack([PON, U[i, :]])\n",
    "                PON_y = np.append(PON_y, NEG[i])\n",
    "\n",
    "        # remove elements of U\n",
    "        U = np.delete(U, index, 0)\n",
    "\n",
    "        if (len(U) == last_U):\n",
    "            break\n",
    "\n",
    "        last_U = len(U)\n",
    "\n",
    "        print(\"size U: \" + str(len(U)) + \" precision: \" + str(precision) + \" all: \" + str(allPrecision))\n",
    "\n",
    "        # add classifier to list of classifiers\n",
    "        FinalWVClassifier.append(new_clf)\n",
    "        FinalWVClassifier_weights.append(precision)\n",
    "\n",
    "    for i in range(0, len(FinalWVClassifier_weights)):\n",
    "        FinalWVClassifier_weights[i] = FinalWVClassifier_weights[i] / allPrecision\n",
    "\n",
    "    print(\"------------------\")\n",
    "    print(\"A weighted voting method with \" + str(len(FinalWVClassifier)) + \" classifiers was created.\")\n",
    "    \n",
    "    return FinalWVClassifier, FinalWVClassifier_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the label of the elements of the given list with the given classifiers and weigths\n",
    "# returns a list with these labels\n",
    "def predict_weighted_voting_list(classifiers, weights, listt):\n",
    "    result = []\n",
    "    for elem in listt:\n",
    "        result.append(predict_weighted_voting(classifiers, weights, elem))\n",
    "    return result\n",
    "    \n",
    "# predict the label of x with the given classifiers and weigths\n",
    "def predict_weighted_voting(classifiers, weigths, x):\n",
    "    score = 0\n",
    "    for i in range(0, len(classifiers)):\n",
    "        score += weigths[i] * classifiers[i].predict([x])\n",
    "    return round(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-DNFII: RN is initialized\n",
      "1-DNFII: PF is constructed\n",
      "1-DNFII: RN was finalized\n",
      "size U: 6014 precision: 0.9588235294117646 all: 0.9588235294117646\n",
      "size U: 5905 precision: 0.9495548961424332 all: 1.9083784255541978\n",
      "size U: 5808 precision: 0.9495548961424332 all: 2.857933321696631\n",
      "size U: 5559 precision: 0.9495548961424332 all: 3.8074882178390643\n",
      "size U: 4811 precision: 0.9464285714285715 all: 4.7539167892676355\n",
      "size U: 3531 precision: 0.936936936936937 all: 5.690853726204573\n",
      "size U: 2229 precision: 0.9207317073170732 all: 6.611585433521646\n",
      "size U: 1262 precision: 0.9107692307692308 all: 7.5223546642908765\n",
      "size U: 734 precision: 0.8726114649681529 all: 8.394966129259029\n",
      "size U: 495 precision: 0.8506493506493507 all: 9.245615479908379\n",
      "size U: 392 precision: 0.8278145695364238 all: 10.073430049444802\n",
      "size U: 348 precision: 0.8200000000000001 all: 10.893430049444802\n",
      "size U: 330 precision: 0.8160535117056855 all: 11.709483561150488\n",
      "size U: 319 precision: 0.8160535117056855 all: 12.525537072856174\n",
      "size U: 311 precision: 0.8160535117056855 all: 13.34159058456186\n",
      "size U: 308 precision: 0.8120805369127517 all: 14.153671121474613\n",
      "size U: 307 precision: 0.8080808080808081 all: 14.96175192955542\n",
      "size U: 306 precision: 0.8080808080808081 all: 15.769832737636229\n",
      "------------------\n",
      "A weighted voting method with 18 classifiers was created.\n",
      "1-DNFII F1 score: 0.7605797101449274\n",
      "1-DNFII: RN is initialized\n",
      "1-DNFII: PF is constructed\n",
      "1-DNFII: RN was finalized\n",
      "size U: 6005 precision: 0.9464285714285715 all: 0.9464285714285715\n",
      "size U: 5911 precision: 0.9337349397590362 all: 1.8801635111876078\n",
      "size U: 5822 precision: 0.9305135951661632 all: 2.810677106353771\n",
      "size U: 5618 precision: 0.9305135951661632 all: 3.741190701519934\n",
      "size U: 5050 precision: 0.9272727272727274 all: 4.668463428792662\n",
      "size U: 3872 precision: 0.9207317073170732 all: 5.589195136109735\n",
      "size U: 2488 precision: 0.9107692307692308 all: 6.499964366878966\n",
      "size U: 1445 precision: 0.8902821316614421 all: 7.3902464985404075\n",
      "size U: 852 precision: 0.8653846153846153 all: 8.255631113925023\n",
      "size U: 551 precision: 0.8355263157894737 all: 9.091157429714498\n",
      "size U: 427 precision: 0.8160535117056855 all: 9.907210941420184\n",
      "size U: 374 precision: 0.8 all: 10.707210941420184\n",
      "size U: 346 precision: 0.7876712328767124 all: 11.494882174296897\n",
      "size U: 335 precision: 0.7835051546391751 all: 12.278387328936073\n",
      "size U: 328 precision: 0.7835051546391751 all: 13.06189248357525\n",
      "size U: 320 precision: 0.7835051546391751 all: 13.845397638214425\n",
      "------------------\n",
      "A weighted voting method with 16 classifiers was created.\n",
      "1-DNFII F1 score: 0.7164634146341464\n",
      "1-DNFII: RN is initialized\n",
      "1-DNFII: PF is constructed\n",
      "1-DNFII: RN was finalized\n",
      "size U: 6025 precision: 0.9432835820895522 all: 0.9432835820895522\n",
      "size U: 5921 precision: 0.9432835820895522 all: 1.8865671641791044\n",
      "size U: 5850 precision: 0.9432835820895522 all: 2.8298507462686566\n",
      "size U: 5675 precision: 0.9432835820895522 all: 3.773134328358209\n",
      "size U: 5168 precision: 0.9432835820895522 all: 4.7164179104477615\n",
      "size U: 4031 precision: 0.9401197604790419 all: 5.656537670926803\n",
      "size U: 2637 precision: 0.9337349397590362 all: 6.590272610685839\n",
      "size U: 1532 precision: 0.9040247678018576 all: 7.494297378487697\n",
      "size U: 880 precision: 0.8617363344051447 all: 8.356033712892842\n",
      "size U: 561 precision: 0.8355263157894737 all: 9.191560028682316\n",
      "size U: 434 precision: 0.8160535117056855 all: 10.007613540388002\n"
     ]
    }
   ],
   "source": [
    "ress = []\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for _ in range(10):\n",
    "    name = \"1-DNFII\"\n",
    "    classifiers, weights = weighted_voting(np.copy(train_x), np.copy(train_y), 0.4, 0.2)\n",
    "    pred_y = predict_weighted_voting_list(classifiers, weights, np.copy(test_x))         \n",
    "    print(name,\"F1 score:\", f1_score(test_y, pred_y))\n",
    "    ress.append(f1_score(test_y, pred_y))\n",
    "\n",
    "    for x in range(0, len(pred_y)):\n",
    "        if (pred_y[x] == 1) and (test_y[x] == 1):\n",
    "            TP += 1\n",
    "        elif (pred_y[x] == 1) and (test_y[x] == 0):\n",
    "            FP += 1\n",
    "        elif (pred_y[x] == 0) and (test_y[x] == 0):\n",
    "            TN += 1\n",
    "        elif (pred_y[x] == 0) and (test_y[x] == 1):\n",
    "            FN += 1\n",
    "print('avg F1: ' + str(sum(ress)/len(ress)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After 10 runs of weighted voting:\")\n",
    "print(\"Average number of TP = \", TP / 10)\n",
    "print(\"Average number of FP = \", FP / 10)\n",
    "print(\"Average number of TN = \", TN / 10)\n",
    "print(\"Avergae number of FN = \", FN / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
