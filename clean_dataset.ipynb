{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns that will be dropped\n",
    "dropped_columns = ['player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'club_name', 'league_name',\n",
    "                  'club_position', 'club_loaned_from', 'club_joined', 'nationality_name', 'nation_position',\n",
    "                  'preferred_foot', 'work_rate', 'body_type', 'real_face', 'player_tags', 'player_traits',\n",
    "                  'player_face_url', 'club_logo_url', 'club_flag_url', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf',\n",
    "                  'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb',\n",
    "                  'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk', 'nation_logo_url', 'nation_flag_url']\n",
    "\n",
    "# define the columns that will be used\n",
    "selected_columns = ['sofifa_id', 'overall', 'age', 'height_cm', 'weight_kg',\n",
    "                    'weak_foot', 'skill_moves', 'pace', 'shooting', 'passing', 'dribbling',\n",
    "                    'defending', 'physic', 'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling','skill_curve',\n",
    "                    'skill_fk_accuracy', 'skill_long_passing' , 'skill_ball_control', 'movement_acceleration',\n",
    "                    'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance',\n",
    "                    'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots',\n",
    "                    'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',\n",
    "                    'defending_standing_tackle', 'defending_sliding_tackle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_injury_prone_array(x_data):\n",
    "    res = np.zeros((len(x_data),), dtype=int)\n",
    "    for i in range(len(x_data)):\n",
    "        if np.isin('Injury Prone',x_data[i]): res[i] = 0\n",
    "        else: res [i] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection-time: 1.36 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# read the 2017 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_17.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "\n",
    "X_2017 = data.iloc[:, :-2].values\n",
    "#data = data.assign(injury_prone = make_injury_prone_array(X_2017))\n",
    "#data = data.drop('player_traits', axis = 1)\n",
    "#X_2017 = data.iloc[:, :-2].values\n",
    "\n",
    "\n",
    "# create a vector with zeros (same length as X_2017)\n",
    "# these are the labels for the 2017 data\n",
    "Y_2017 = np.zeros((len(X_2017),), dtype=int)\n",
    "\n",
    "# read the 2018 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_18.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2018 = data.iloc[:, :-2].values\n",
    "#data = data.assign(injury_prone = make_injury_prone_array(X_2018))\n",
    "#data = data.drop('player_traits', axis = 1)\n",
    "#X_2018 = data.iloc[:, :-2].values\n",
    "\n",
    "# read the 2019 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_19.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2019 = data.iloc[:, :-2].values\n",
    "#data = data.assign(injury_prone = make_injury_prone_array(X_2019))\n",
    "#data = data.drop('player_traits', axis = 1)\n",
    "#X_2019 = data.iloc[:, :-2].values\n",
    "\n",
    "# read the 2020 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_20.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2020 = data.iloc[:, :-2].values\n",
    "#data = data.assign(injury_prone = make_injury_prone_array(X_2020))\n",
    "#data = data.drop('player_traits', axis = 1)\n",
    "#X_2020 = data.iloc[:, :-2].values\n",
    "\n",
    "# read the 2021 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_21.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2021 = data.iloc[:, :-2].values\n",
    "#data = data.assign(injury_prone = make_injury_prone_array(X_2021))\n",
    "#data = data.drop('player_traits', axis = 1)\n",
    "#X_2021 = data.iloc[:, :-2].values\n",
    "\n",
    "# read the 2022 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_22.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2022 = data.iloc[:, :-2].values\n",
    "#data = data.assign(injury_prone = make_injury_prone_array(X_2022))\n",
    "#data = data.drop('player_traits', axis = 1)\n",
    "#X_2022 = data.iloc[:, :-2].values\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Selection-time: \" + str(round(t1 - t0, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# select the column with the average rating\n",
    "AVG = X_2022[:, 1]\n",
    "\n",
    "# highest AVG in the game\n",
    "max_AVG = np.amax(AVG)\n",
    "\n",
    "# rating such that 95% of data is lower than this rating \n",
    "rating_highest_percent = np.percentile(AVG, 90)\n",
    "# rating such that 10% of data is lower than this rating \n",
    "rating_lowest_percent = np.percentile(AVG, 10)\n",
    "\n",
    "print(rating_highest_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling-time: 104.64 seconds\n",
      "Number of positive examples: 2680\n",
      "Number of unlabeled examples: 12923\n"
     ]
    }
   ],
   "source": [
    "# loop over every row in the 2022 data\n",
    "# if a player has an average rating that is higher or equal to the rating such that 95% of data \n",
    "# is lower than this rating , then mark this player as a positive example in the 2017 data\n",
    "# the first element of a row is a unique id (for a given player, this id is the same in every version of fifa)\n",
    "t0 = time.time()\n",
    "\n",
    "for i in range(0, len(X_2018)):\n",
    "    if (int(X_2018[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2018[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "\n",
    "for i in range(0, len(X_2019)):\n",
    "    if (int(X_2019[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2019[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "\n",
    "for i in range(0, len(X_2020)):\n",
    "    if (int(X_2020[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2020[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "                \n",
    "for i in range(0, len(X_2021)):\n",
    "    if (int(X_2021[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2021[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "                \n",
    "for i in range(0, len(X_2022)):\n",
    "    if (int(X_2022[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2022[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "                \n",
    "t1 = time.time()\n",
    "print(\"Labelling-time: \" + str(round(t1-t0, 2)) + \" seconds\")\n",
    "                \n",
    "# print the number of positive and negative examples\n",
    "print(f\"Number of positive examples: {Counter(Y_2017)[1]}\")\n",
    "print(f\"Number of unlabeled examples: {Counter(Y_2017)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sofifa_id_column\n",
    "sofifa_id = X_2017[:, 0]\n",
    "\n",
    "# remove sofifa_id column\n",
    "X_2017 = np.delete(X_2017, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values:\n",
      "[[1.         0.55555556 0.6122449  ... 0.87058824 0.89473684 0.14634146]\n",
      " [0.97959184 0.48148148 0.30612245 ... 0.74117647 1.         0.03658537]\n",
      " [0.95918367 0.48148148 0.55102041 ... 0.87058824 0.85526316 0.24390244]\n",
      " ...\n",
      " [0.         0.07407407 0.57142857 ... 0.4        0.42105263 0.32926829]\n",
      " [0.         0.11111111 0.20408163 ... 0.17647059 0.43421053 0.34146341]\n",
      " [0.         0.07407407 0.30612245 ... 0.10588235 0.35526316 0.06097561]]\n",
      "False\n",
      "True\n",
      "[ True False False False False  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True False  True False  True False  True  True  True  True  True\n",
      "  True  True  True]\n",
      "39\n",
      "39\n",
      "(array([ 1,  2,  3,  4,  6, 22, 26, 28, 30]),)\n",
      "[[1.         1.         1.         ... 0.87058824 0.89473684 0.14634146]\n",
      " [0.97959184 0.66666667 0.97435897 ... 0.74117647 1.         0.03658537]\n",
      " [0.95918367 0.66666667 0.97435897 ... 0.87058824 0.85526316 0.24390244]\n",
      " ...\n",
      " [0.         0.33333333 0.34615385 ... 0.4        0.42105263 0.32926829]\n",
      " [0.         0.         0.25641026 ... 0.17647059 0.43421053 0.34146341]\n",
      " [0.         0.33333333 0.23076923 ... 0.10588235 0.35526316 0.06097561]]\n",
      "(15603, 30)\n"
     ]
    }
   ],
   "source": [
    "# normalize values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_2017 = min_max_scaler.fit_transform(X_2017)\n",
    "print(\"Normalized values:\")\n",
    "print(X_2017)\n",
    "\n",
    "'''\n",
    "# select most important features based on chi-squared method\n",
    "number_of_features = 30\n",
    "chi_selector = SelectKBest(chi2, k=number_of_features)\n",
    "chi_selector.fit(X_2017, Y_2017)\n",
    "chi_support = chi_selector.get_support()\n",
    "\n",
    "# keep only relevent features in X_2017\n",
    "column_indices_to_drop = np.where(chi_support == False)\n",
    "new_X_2017 = np.zeros((X_2017.shape[0],number_of_features))\n",
    "for i in range(len(X_2017)):\n",
    "    new_X_2017[i] = np.delete(X_2017[i], column_indices_to_drop)\n",
    "X_2017 = new_X_2017\n",
    "'''\n",
    "\n",
    "# add sofifa_id column\n",
    "X_2017 = np.hstack((sofifa_id[:, np.newaxis], X_2017))\n",
    "\n",
    "# the labels (that indicate if an instance is positive or negative (unlabeled in this case)) \n",
    "# are stacked together into one matrix\n",
    "X_2017_array = np.array(X_2017)\n",
    "Y_2017_array = np.array(Y_2017)\n",
    "result = np.column_stack((X_2017_array, Y_2017_array))\n",
    "\n",
    "# every occurence of NaN is replaced by zero\n",
    "result[np.isnan(result)] = 0\n",
    "\n",
    "# the data is cleaned and written to a file\n",
    "np.savetxt(\"clean_data/players_17_clean.csv\", result, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create-test-set-time: 43.9 seconds\n",
      "1490 elements were removed from the test set\n",
      "Number of training examples: 10297\n",
      "Number of testing examples: 3815\n"
     ]
    }
   ],
   "source": [
    "# creating a train and a test set\n",
    "\n",
    "# cleaned data that was created in the previous block is read and randomly devided into two classes: train and test\n",
    "# 2/3 of the examples are in the training set\n",
    "# 1/3 of the examples are in the test set\n",
    "clean_data = pd.read_csv('clean_data/players_17_clean.csv')\n",
    "training_data = clean_data.sample(frac=0.66, random_state=25)\n",
    "testing_data = clean_data.drop(training_data.index)\n",
    "\n",
    "testing_data = testing_data.values\n",
    "training_data = training_data.values\n",
    "\n",
    "# because negative labeled examples are in fact unlabeled examples in our case, we can't be sure that they are \n",
    "# indeed negative\n",
    "# if a player doesn't appear in fifa 2022, we can label him as negative\n",
    "# if a player belongs to the top 10% worst players in fifa 2022, we can also label him as negative\n",
    "before = len(testing_data)\n",
    "t0 = time.time()\n",
    "\n",
    "index = []\n",
    "\n",
    "# rating_lowest_percent is divided by 100\n",
    "for i in range(0, len(testing_data)):\n",
    "    if (int(testing_data[i][-1]) == 0):\n",
    "        for j in range(0, len(X_2022)):\n",
    "            if (X_2022[j][0] == testing_data[i][0]) and (X_2022[j][1] > rating_lowest_percent):\n",
    "                index.append(i)\n",
    "                break\n",
    "                \n",
    "testing_data = np.delete(testing_data, index, 0)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Create-test-set-time: \" + str(round(t1-t0, 2)) + \" seconds\")\n",
    "\n",
    "after = len(testing_data)\n",
    "print(str(before - after) + \" elements were removed from the test set\")\n",
    "\n",
    "# remove sofifa_id column\n",
    "training_data = np.delete(training_data, 0, 1)\n",
    "testing_data = np.delete(testing_data, 0, 1)\n",
    "\n",
    "# print the number of training and test examples\n",
    "print(f\"Number of training examples: {training_data.shape[0]}\")\n",
    "print(f\"Number of testing examples: {testing_data.shape[0]}\")\n",
    "\n",
    "# write the training and test examples to two seperate files\n",
    "np.savetxt(\"clean_data/players_17_clean_train.csv\", training_data, delimiter=\",\")\n",
    "np.savetxt(\"clean_data/players_17_clean_test.csv\", testing_data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
