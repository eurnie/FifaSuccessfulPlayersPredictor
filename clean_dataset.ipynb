{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns that will be dropped\n",
    "dropped_columns = ['player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'club_name', 'league_name',\n",
    "                  'club_position', 'club_loaned_from', 'club_joined', 'nationality_name', 'nation_position',\n",
    "                  'preferred_foot', 'work_rate', 'body_type', 'real_face', 'player_tags', 'player_traits',\n",
    "                  'player_face_url', 'club_logo_url', 'club_flag_url', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf',\n",
    "                  'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb',\n",
    "                  'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk', 'nation_logo_url', 'nation_flag_url']\n",
    "\n",
    "# define the columns that will be used\n",
    "selected_columns = ['sofifa_id', 'overall', 'age', 'height_cm', 'weight_kg', 'league_level',\n",
    "                    'weak_foot', 'skill_moves', 'pace', 'shooting', 'passing', 'dribbling',\n",
    "                    'defending', 'physic', 'club_position', 'player_traits']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_injury_prone_array(x_data):\n",
    "    res = np.zeros((len(x_data),), dtype=int)\n",
    "    for i in range(len(x_data)):\n",
    "        #print(x_data)\n",
    "        if np.isin('Injury Prone',x_data[i]): res[i] = 0\n",
    "        else: res [i] = 1\n",
    "    return res\n",
    "\n",
    "def count_player_tags(x_data):\n",
    "    res = np.zeros((len(x_data),), dtype=int)\n",
    "    for i in range(len(x_data)):\n",
    "        player_tags = x_data[i][-1]\n",
    "        if isinstance(player_tags, str):\n",
    "            res[i] = len(player_tags.split(','))\n",
    "    return res\n",
    "\n",
    "def encode_position_into_number(x_data):\n",
    "    res = np.zeros((len(x_data),), dtype=int)\n",
    "    forward_positions = ['RF','LF','CF','ST']\n",
    "    midfield_positions = ['LW','RW','CAM','CM','CDM']\n",
    "    defending_positions = ['RB','LB','RWB','LWB','CB']\n",
    "    for i in range(len(x_data)):\n",
    "        club_position = x_data[i][-1]\n",
    "        if np.isin(True,np.isin(forward_positions,club_position)): res[i] = 0\n",
    "        elif np.isin(True,np.isin(midfield_positions,club_position)): res[i] = 1\n",
    "        else: res[i] = 2\n",
    "    return res\n",
    "\n",
    "def average_columns(x_data, columns):\n",
    "    res = np.zeros((len(x_data),), dtype=int)\n",
    "    for i in range(len(x_data)):\n",
    "        summ = 0\n",
    "        for j in range(len(columns)): \n",
    "            summ += x_data[i][columns[j]]\n",
    "        res[i] = summ/(j+1)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "x_2017: [[2.08010e+04 9.40000e+01 3.10000e+01 ... 8.00000e+01 1.00000e+00\n",
      "  2.00000e+00]\n",
      " [1.58023e+05 9.30000e+01 2.90000e+01 ... 6.10000e+01 1.00000e+00\n",
      "  2.00000e+00]\n",
      " [1.76580e+05 9.20000e+01 2.90000e+01 ... 7.90000e+01 1.00000e+00\n",
      "  2.00000e+00]\n",
      " ...\n",
      " [2.34069e+05 4.50000e+01 1.80000e+01 ... 5.20000e+01 1.00000e+00\n",
      "  2.00000e+00]\n",
      " [2.34353e+05 4.50000e+01 1.90000e+01 ... 5.10000e+01 1.00000e+00\n",
      "  2.00000e+00]\n",
      " [2.34733e+05 4.50000e+01 1.80000e+01 ... 4.70000e+01 1.00000e+00\n",
      "  2.00000e+00]]\n",
      "Selection-time: 21.25 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#------\n",
    "## 2017\n",
    "#------\n",
    "# read the 2017 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_17.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "\n",
    "#print(data['player_tags'])\n",
    "X_2017 = data.iloc[:, :].values\n",
    "# construct player_tag_count column\n",
    "#data = data.assign(player_tags_count = count_player_tags(X_2017))\n",
    "#data = data.drop('player_tags', axis = 'columns')\n",
    "# construct injury_prone column\n",
    "data = data.assign(injury_prone = make_injury_prone_array(X_2017))\n",
    "data = data.drop('player_traits', axis = 'columns')\n",
    "# construct position column\n",
    "data = data.assign(player_position = encode_position_into_number(X_2017))\n",
    "data = data.drop('club_position', axis = 'columns')\n",
    "# construct summarized attacking\n",
    "'''\n",
    "attacking_stats = [14, 15, 16, 17, 18]\n",
    "movement_stats = [19, 20, 21, 22, 23]\n",
    "power_stats = [24, 25, 26, 27, 28]\n",
    "mentality_stats = [29, 30, 31, 32, 33, 34]\n",
    "\n",
    "print(average_columns(X_2017,attacking_stats))\n",
    "print(average_columns(X_2017,movement_stats))\n",
    "print(average_columns(X_2017,power_stats))\n",
    "print(average_columns(X_2017,mentality_stats))\n",
    "\n",
    "# build new columns\n",
    "new_attacking_column = average_columns(X_2017,attacking_stats)\n",
    "new_movement_column = average_columns(X_2017,movement_stats)\n",
    "new_power_column = average_columns(X_2017,power_stats)\n",
    "new_mentality_column = average_columns(X_2017,mentality_stats)\n",
    "\n",
    "# drop old columns\n",
    "data = data.drop(['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys'], axis = 'columns')\n",
    "data = data.drop(['movement_acceleration','movement_sprint_speed', 'movement_agility',\n",
    "                  'movement_reactions','movement_balance'], axis = 'columns')\n",
    "data = data.drop(['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                  'power_long_shots'], axis = 'columns')\n",
    "data = data.drop(['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure'], axis = 'columns')\n",
    "\n",
    "# assign new columns\n",
    "data = data.assign(attacking = new_attacking_column)\n",
    "data = data.assign(movement = new_movement_column)\n",
    "data = data.assign(power = new_power_column)\n",
    "data = data.assign(mentality = new_mentality_column)\n",
    "print(len(data.columns))\n",
    "'''\n",
    "\n",
    "data = data.dropna()     #drop all rows that have any NaN values: results in 2187 removed players\n",
    "X_2017 = data.values\n",
    "print(X_2017[0][-1])\n",
    "print('x_2017: ' + str(X_2017))\n",
    "# create a vector with zeros (same length as X_2017)\n",
    "# these are the labels for the 2017 data\n",
    "Y_2017 = np.zeros((len(X_2017),), dtype=int)\n",
    "\n",
    "\n",
    "#------\n",
    "## 2018\n",
    "#------\n",
    "# read the 2018 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_18.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "\n",
    "X_2018 = data.iloc[:, :].values\n",
    "# construct player_tag_count column\n",
    "#data = data.assign(player_tags_count = count_player_tags(X_2018))\n",
    "#data = data.drop('player_tags', axis = 'columns')\n",
    "# construct injury_prone column\n",
    "data = data.assign(injury_prone = make_injury_prone_array(X_2018))\n",
    "data = data.drop('player_traits', axis = 'columns')\n",
    "# construct position column\n",
    "data = data.assign(player_position = encode_position_into_number(X_2018))\n",
    "data = data.drop('club_position', axis = 'columns')\n",
    "# construct summarized attacking\n",
    "# build new columns\n",
    "'''\n",
    "new_attacking_column = average_columns(X_2018,attacking_stats)\n",
    "new_movement_column = average_columns(X_2018,movement_stats)\n",
    "new_power_column = average_columns(X_2018,power_stats)\n",
    "new_mentality_column = average_columns(X_2018,mentality_stats)\n",
    "\n",
    "# drop old columns\n",
    "data = data.drop(['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys'], axis = 'columns')\n",
    "data = data.drop(['movement_acceleration','movement_sprint_speed', 'movement_agility',\n",
    "                  'movement_reactions','movement_balance'], axis = 'columns')\n",
    "data = data.drop(['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                  'power_long_shots'], axis = 'columns')\n",
    "data = data.drop(['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure'], axis = 'columns')\n",
    "\n",
    "# assign new columns\n",
    "data = data.assign(attacking = new_attacking_column)\n",
    "data = data.assign(movement = new_movement_column)\n",
    "data = data.assign(power = new_power_column)\n",
    "data = data.assign(mentality = new_mentality_column)\n",
    "'''\n",
    "\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2018 = data.iloc[:, :].values\n",
    "\n",
    "# read the 2019 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_19.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "\n",
    "X_2019 = data.iloc[:, :].values\n",
    "# construct player_tag_count column\n",
    "#data = data.assign(player_tags_count = count_player_tags(X_2019))\n",
    "#data = data.drop('player_tags', axis = 'columns')\n",
    "# construct injury_prone column\n",
    "data = data.assign(injury_prone = make_injury_prone_array(X_2019))\n",
    "data = data.drop('player_traits', axis = 'columns')\n",
    "# construct position column\n",
    "data = data.assign(player_position = encode_position_into_number(X_2019))\n",
    "data = data.drop('club_position', axis = 'columns')\n",
    "# construct summarized attacking\n",
    "# build new columns\n",
    "'''\n",
    "new_attacking_column = average_columns(X_2019,attacking_stats)\n",
    "new_movement_column = average_columns(X_2019,movement_stats)\n",
    "new_power_column = average_columns(X_2019,power_stats)\n",
    "new_mentality_column = average_columns(X_2019,mentality_stats)\n",
    "\n",
    "# drop old columns\n",
    "data = data.drop(['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys'], axis = 'columns')\n",
    "data = data.drop(['movement_acceleration','movement_sprint_speed', 'movement_agility',\n",
    "                  'movement_reactions','movement_balance'], axis = 'columns')\n",
    "data = data.drop(['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                  'power_long_shots'], axis = 'columns')\n",
    "data = data.drop(['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure'], axis = 'columns')\n",
    "\n",
    "# assign new columns\n",
    "data = data.assign(attacking = new_attacking_column)\n",
    "data = data.assign(movement = new_movement_column)\n",
    "data = data.assign(power = new_power_column)\n",
    "data = data.assign(mentality = new_mentality_column)\n",
    "'''\n",
    "\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2019 = data.iloc[:, :].values\n",
    "\n",
    "# read the 2020 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_20.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "\n",
    "X_2020 = data.iloc[:, :].values\n",
    "# construct player_tag_count column\n",
    "#data = data.assign(player_tags_count = count_player_tags(X_2020))\n",
    "#data = data.drop('player_tags', axis = 'columns')\n",
    "# construct injury_prone column\n",
    "data = data.assign(injury_prone = make_injury_prone_array(X_2020))\n",
    "data = data.drop('player_traits', axis = 'columns')\n",
    "# construct position column\n",
    "data = data.assign(player_position = encode_position_into_number(X_2020))\n",
    "data = data.drop('club_position', axis = 'columns')\n",
    "# construct summarized attacking\n",
    "# build new columns\n",
    "'''\n",
    "new_attacking_column = average_columns(X_2020,attacking_stats)\n",
    "new_movement_column = average_columns(X_2020,movement_stats)\n",
    "new_power_column = average_columns(X_2020,power_stats)\n",
    "new_mentality_column = average_columns(X_2020,mentality_stats)\n",
    "\n",
    "# drop old columns\n",
    "data = data.drop(['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys'], axis = 'columns')\n",
    "data = data.drop(['movement_acceleration','movement_sprint_speed', 'movement_agility',\n",
    "                  'movement_reactions','movement_balance'], axis = 'columns')\n",
    "data = data.drop(['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                  'power_long_shots'], axis = 'columns')\n",
    "data = data.drop(['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure'], axis = 'columns')\n",
    "'''\n",
    "\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2020 = data.iloc[:, :].values\n",
    "\n",
    "# read the 2021 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_21.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "\n",
    "X_2021 = data.iloc[:, :].values\n",
    "# construct player_tag_count column\n",
    "#data = data.assign(player_tags_count = count_player_tags(X_2021))\n",
    "#data = data.drop('player_tags', axis = 'columns')\n",
    "# construct injury_prone column\n",
    "data = data.assign(injury_prone = make_injury_prone_array(X_2021))\n",
    "data = data.drop('player_traits', axis = 'columns')\n",
    "# construct position column\n",
    "data = data.assign(player_position = encode_position_into_number(X_2021))\n",
    "data = data.drop('club_position', axis = 'columns')\n",
    "# construct summarized attacking\n",
    "# build new columns\n",
    "'''\n",
    "new_attacking_column = average_columns(X_2021,attacking_stats)\n",
    "new_movement_column = average_columns(X_2021,movement_stats)\n",
    "new_power_column = average_columns(X_2021,power_stats)\n",
    "new_mentality_column = average_columns(X_2021,mentality_stats)\n",
    "\n",
    "# drop old columns\n",
    "data = data.drop(['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys'], axis = 'columns')\n",
    "data = data.drop(['movement_acceleration','movement_sprint_speed', 'movement_agility',\n",
    "                  'movement_reactions','movement_balance'], axis = 'columns')\n",
    "data = data.drop(['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                  'power_long_shots'], axis = 'columns')\n",
    "data = data.drop(['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure'], axis = 'columns')\n",
    "'''\n",
    "\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2021 = data.iloc[:, :].values\n",
    "\n",
    "# read the 2022 data from the .csv file and drop the columns defined above\n",
    "data = pd.read_csv('original_data/players_22.csv')\n",
    "#data = data.drop(dropped_columns, axis = 1)\n",
    "data = data[selected_columns]\n",
    "\n",
    "X_2022 = data.iloc[:, :].values\n",
    "# construct player_tag_count column\n",
    "#data = data.assign(player_tags_count = count_player_tags(X_2022))\n",
    "#data = data.drop('player_tags', axis = 'columns')\n",
    "# construct injury_prone column\n",
    "data = data.assign(injury_prone = make_injury_prone_array(X_2022))\n",
    "data = data.drop('player_traits', axis = 'columns')\n",
    "# construct position column\n",
    "data = data.assign(player_position = encode_position_into_number(X_2022))\n",
    "data = data.drop('club_position', axis = 'columns')\n",
    "# construct summarized attacking\n",
    "# build new columns\n",
    "'''\n",
    "new_attacking_column = average_columns(X_2022,attacking_stats)\n",
    "new_movement_column = average_columns(X_2022,movement_stats)\n",
    "new_power_column = average_columns(X_2022,power_stats)\n",
    "new_mentality_column = average_columns(X_2022,mentality_stats)\n",
    "\n",
    "# drop old columns\n",
    "data = data.drop(['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',\n",
    "                    'attacking_short_passing', 'attacking_volleys'], axis = 'columns')\n",
    "data = data.drop(['movement_acceleration','movement_sprint_speed', 'movement_agility',\n",
    "                  'movement_reactions','movement_balance'], axis = 'columns')\n",
    "data = data.drop(['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength',\n",
    "                  'power_long_shots'], axis = 'columns')\n",
    "data = data.drop(['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision',\n",
    "                    'mentality_penalties', 'mentality_composure'], axis = 'columns')\n",
    "'''\n",
    "\n",
    "data = data.dropna()     #drop all rows that have any NaN values\n",
    "X_2022 = data.iloc[:, :].values\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Selection-time: \" + str(round(t1 - t0, 2)) + \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "# select the column with the average rating\n",
    "AVG = X_2022[:, 1]\n",
    "\n",
    "# highest AVG in the game\n",
    "max_AVG = np.amax(AVG)\n",
    "\n",
    "# rating such that 95% of data is lower than this rating \n",
    "rating_highest_percent = np.percentile(AVG, 90)\n",
    "# rating such that 10% of data is lower than this rating \n",
    "rating_lowest_percent = np.percentile(AVG, 10)\n",
    "\n",
    "print(rating_highest_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling-time: 108.67 seconds\n",
      "Number of positive examples: 2640\n",
      "Number of unlabeled examples: 12769\n"
     ]
    }
   ],
   "source": [
    "# loop over every row in the 2022 data\n",
    "# if a player has an average rating that is higher or equal to the rating such that 95% of data \n",
    "# is lower than this rating , then mark this player as a positive example in the 2017 data\n",
    "# the first element of a row is a unique id (for a given player, this id is the same in every version of fifa)\n",
    "t0 = time.time()\n",
    "\n",
    "for i in range(0, len(X_2018)):\n",
    "    if (int(X_2018[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2018[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "\n",
    "for i in range(0, len(X_2019)):\n",
    "    if (int(X_2019[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2019[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "\n",
    "for i in range(0, len(X_2020)):\n",
    "    if (int(X_2020[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2020[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "                \n",
    "for i in range(0, len(X_2021)):\n",
    "    if (int(X_2021[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2021[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "                \n",
    "for i in range(0, len(X_2022)):\n",
    "    if (int(X_2022[i][1]) >= rating_highest_percent):\n",
    "        for j in range(0, len(X_2017)):\n",
    "            if (X_2017[j][0] == X_2022[i][0]):\n",
    "                Y_2017[j] = 1\n",
    "                \n",
    "t1 = time.time()\n",
    "print(\"Labelling-time: \" + str(round(t1-t0, 2)) + \" seconds\")\n",
    "                \n",
    "# print the number of positive and negative examples\n",
    "print(f\"Number of positive examples: {Counter(Y_2017)[1]}\")\n",
    "print(f\"Number of unlabeled examples: {Counter(Y_2017)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sofifa_id_column\n",
    "sofifa_id = X_2017[:, 0]\n",
    "\n",
    "# remove sofifa_id column\n",
    "X_2017 = np.delete(X_2017, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values:\n",
      "[[1.         0.55555556 0.6122449  ... 0.84126984 1.         0.        ]\n",
      " [0.97959184 0.48148148 0.30612245 ... 0.53968254 1.         0.        ]\n",
      " [0.95918367 0.48148148 0.55102041 ... 0.82539683 1.         0.        ]\n",
      " ...\n",
      " [0.         0.07407407 0.57142857 ... 0.3968254  1.         0.        ]\n",
      " [0.         0.11111111 0.20408163 ... 0.38095238 1.         0.        ]\n",
      " [0.         0.07407407 0.30612245 ... 0.31746032 1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# normalize values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_2017 = min_max_scaler.fit_transform(X_2017)\n",
    "print(\"Normalized values:\")\n",
    "print(X_2017)\n",
    "\n",
    "'''\n",
    "# select most important features based on chi-squared method\n",
    "number_of_features = 10\n",
    "chi_selector = SelectKBest(chi2, k=number_of_features)\n",
    "chi_selector.fit(X_2017, Y_2017)\n",
    "chi_support = chi_selector.get_support()\n",
    "\n",
    "# keep only relevent features in X_2017\n",
    "column_indices_to_drop = np.where(chi_support == False)\n",
    "new_X_2017 = np.zeros((X_2017.shape[0],number_of_features))\n",
    "for i in range(len(X_2017)):\n",
    "    new_X_2017[i] = np.delete(X_2017[i], column_indices_to_drop)\n",
    "X_2017 = new_X_2017\n",
    "'''\n",
    "\n",
    "# add sofifa_id column\n",
    "X_2017 = np.hstack((sofifa_id[:, np.newaxis], X_2017))\n",
    "\n",
    "# the labels (that indicate if an instance is positive or negative (unlabeled in this case)) \n",
    "# are stacked together into one matrix\n",
    "X_2017_array = np.array(X_2017)\n",
    "Y_2017_array = np.array(Y_2017)\n",
    "result = np.column_stack((X_2017_array, Y_2017_array))\n",
    "\n",
    "# every occurence of NaN is replaced by zero\n",
    "result[np.isnan(result)] = 0\n",
    "\n",
    "# the data is cleaned and written to a file\n",
    "np.savetxt(\"clean_data/players_17_clean.csv\", result, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create-test-set-time: 46.29 seconds\n",
      "1536 elements were removed from the test set\n",
      "Number of training examples: 10169\n",
      "Number of testing examples: 3703\n"
     ]
    }
   ],
   "source": [
    "# creating a train and a test set\n",
    "\n",
    "# cleaned data that was created in the previous block is read and randomly devided into two classes: train and test\n",
    "# 2/3 of the examples are in the training set\n",
    "# 1/3 of the examples are in the test set\n",
    "clean_data = pd.read_csv('clean_data/players_17_clean.csv')\n",
    "training_data = clean_data.sample(frac=0.66, random_state=25)\n",
    "testing_data = clean_data.drop(training_data.index)\n",
    "\n",
    "testing_data = testing_data.values\n",
    "training_data = training_data.values\n",
    "\n",
    "# because negative labeled examples are in fact unlabeled examples in our case, we can't be sure that they are \n",
    "# indeed negative\n",
    "# if a player doesn't appear in fifa 2022, we can label him as negative\n",
    "# if a player belongs to the top 10% worst players in fifa 2022, we can also label him as negative\n",
    "before = len(testing_data)\n",
    "t0 = time.time()\n",
    "\n",
    "index = []\n",
    "\n",
    "# rating_lowest_percent is divided by 100\n",
    "for i in range(0, len(testing_data)):\n",
    "    if (int(testing_data[i][-1]) == 0):\n",
    "        for j in range(0, len(X_2022)):\n",
    "            if (X_2022[j][0] == testing_data[i][0]) and (X_2022[j][1] > rating_lowest_percent):\n",
    "                index.append(i)\n",
    "                break\n",
    "                \n",
    "testing_data = np.delete(testing_data, index, 0)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Create-test-set-time: \" + str(round(t1-t0, 2)) + \" seconds\")\n",
    "\n",
    "after = len(testing_data)\n",
    "print(str(before - after) + \" elements were removed from the test set\")\n",
    "\n",
    "# remove sofifa_id column\n",
    "training_data = np.delete(training_data, 0, 1)\n",
    "testing_data = np.delete(testing_data, 0, 1)\n",
    "\n",
    "# print the number of training and test examples\n",
    "print(f\"Number of training examples: {training_data.shape[0]}\")\n",
    "print(f\"Number of testing examples: {testing_data.shape[0]}\")\n",
    "\n",
    "# write the training and test examples to two seperate files\n",
    "np.savetxt(\"clean_data/players_17_clean_train.csv\", training_data, delimiter=\",\")\n",
    "np.savetxt(\"clean_data/players_17_clean_test.csv\", testing_data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
