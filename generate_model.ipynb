{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, mean_squared_error as mse\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()\n",
    "\n",
    "from PU_Learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('players_17_clean_train.csv')\n",
    "X1_train= data.iloc[:, :-1].values\n",
    "y1_train = data.iloc[:, -1].values\n",
    "s1 = data.iloc[:, -1].values\n",
    "c1 = Counter(s1)[1]/Counter(y1_train)[1]\n",
    "\n",
    "data = pd.read_csv('players_17_clean_test.csv')\n",
    "X1_test= data.iloc[:, :-1].values\n",
    "y1_test = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 150})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golden Standard Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Standard Classifier: F1 score: 0.2758620689655173\n"
     ]
    }
   ],
   "source": [
    "# Consider the dataset as fully labeled. Use this as the best case in the comparison.\n",
    "\n",
    "golden_clf = svm.SVC(kernel='rbf',probability=True,random_state = 331).fit(np.copy(X1_train),np.copy(y1_train))\n",
    "name = \"Golden Standard Classifier:\"\n",
    "\n",
    "y_best_pred_1 = golden_clf.predict(np.copy(X1_test))\n",
    "y_best_prob_1 = golden_clf.predict_proba(np.copy(X1_test))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_best_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Traditional Classifier (first dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Traditional Classifier F1 score: 0.2758620689655173\n",
      "Non-Traditional Classifier MSE score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Fit a model on (X, s1) and see the performance. Compare it with the two methods.\n",
    "non_trad_clf = svm.SVC(kernel='rbf', probability=True, random_state = 331).fit(np.copy(X1_train),np.copy(s1))\n",
    "name = \"Non-Traditional Classifier\"\n",
    "\n",
    "y_pred = non_trad_clf.predict(np.copy(X1_test))\n",
    "y_pred_prob = non_trad_clf.predict_proba(np.copy(X1_test))[:,1]\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob_1, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spy Expectation Maximization S-EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations first step: 786\n",
      "Number of iterations second step: 581\n",
      "SEM F1 score: 1.0\n",
      "SEM MSE score: 0.7118504579726814\n"
     ]
    }
   ],
   "source": [
    "pu_classifier = SEM(tol = 1.0e-10, max_iter = 10000, spy_prop = 0.1, l = 0.15,\n",
    "                    classifier = LogisticRegression(), seed=331)\n",
    "name = \"SEM\"\n",
    "\n",
    "pu_classifier.fit(np.copy(X1_train), np.copy(s1))\n",
    "\n",
    "y_pred = pu_classifier.predict(np.copy(X1_test))\n",
    "\n",
    "y_pred_prob = pu_classifier.predict_proba(np.copy(X1_test))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob_1, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Logistic Regression MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_b 12.003\n",
      "parameter_w [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "log-likelihood -1596.2726101803817\n",
      "MLR F1 score: 1.0\n",
      "MLR MSE score: 0.8156439219978434\n"
     ]
    }
   ],
   "source": [
    "from PU_Learning import *\n",
    "\n",
    "pu_classifier = ModifiedLogisticRegression(max_iter = 10000, l_rate = 0.001, seed = 331)\n",
    "name = \"MLR\"\n",
    "\n",
    "pu_classifier.parameters_update(np.copy(X1_train), np.copy(s1))\n",
    "print(\"parameter_b\", pu_classifier.b)\n",
    "print(\"parameter_w\", pu_classifier.w)\n",
    "print(\"log-likelihood\", pu_classifier.log_likelihood(np.copy(X1_train), np.copy(s1)))\n",
    "\n",
    "pu_classifier.fit(np.copy(X1_train), np.copy(s1))\n",
    "\n",
    "pu_classifier.estimate_c()\n",
    "\n",
    "y_pred = pu_classifier.predict(np.copy(X1_test))\n",
    "\n",
    "y_pred_prob = pu_classifier.predict_proba(np.copy(X1_test))\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob_1, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
