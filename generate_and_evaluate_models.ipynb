{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d04e8ce",
   "metadata": {},
   "source": [
    "# Generate and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d334e",
   "metadata": {},
   "source": [
    "### Import training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94262d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, mean_squared_error as mse\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PU_Learning import *\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ea45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "data = pd.read_csv('clean_data/players_17_clean_train.csv')\n",
    "train_x = data.iloc[:, :-1].values\n",
    "train_y = data.iloc[:, -1].values\n",
    "s = data.iloc[:, -1].values\n",
    "c = Counter(s)[1]/Counter(train_y)[1]\n",
    "\n",
    "# import test data \n",
    "data = pd.read_csv('clean_data/players_17_clean_test.csv')\n",
    "test_x = data.iloc[:, :-1].values\n",
    "test_y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5150b7af",
   "metadata": {},
   "source": [
    "### Golden Standard Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fcbe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Standard Classifier: F1 score: 0.6432673899170389\n"
     ]
    }
   ],
   "source": [
    "# consider the dataset as fully labeled and use this as the best case in the comparison.\n",
    "golden_clf = svm.SVC(kernel='rbf', probability=True, random_state=331).fit(np.copy(train_x),np.copy(train_y))\n",
    "name = \"Golden Standard Classifier:\"\n",
    "\n",
    "best_pred_y = golden_clf.predict(np.copy(test_x))\n",
    "best_prob_y = golden_clf.predict_proba(np.copy(test_x))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(test_y, best_pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae113f",
   "metadata": {},
   "source": [
    "### Non-Traditional Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_trad_clf = svm.SVC(kernel='rbf', probability=True, random_state=331).fit(np.copy(train_x), np.copy(s))\n",
    "name = \"Non-Traditional Classifier\"\n",
    "\n",
    "pred_y = non_trad_clf.predict(np.copy(test_x))\n",
    "pred_prob_y = non_trad_clf.predict_proba(np.copy(test_x))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(test_y, pred_y))\n",
    "print(name,\"MSE score:\", mse(best_prob_y, pred_prob_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01957ab5",
   "metadata": {},
   "source": [
    "### Spy Expectation Maximization S-EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_classifier = SEM(tol=1.0e-10, max_iter=1000, spy_prop=0.1, l=0.15, classifier=LogisticRegression(), seed=331)\n",
    "name = \"SEM\"\n",
    "\n",
    "pu_classifier.fit(np.copy(train_x), np.copy(s))\n",
    "\n",
    "pred_y = pu_classifier.predict(np.copy(test_x))\n",
    "pred_prob_y = pu_classifier.predict_proba(np.copy(test_x))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(test_y, pred_y))\n",
    "print(name,\"MSE score:\", mse(best_prob_y, pred_prob_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc252db",
   "metadata": {},
   "source": [
    "### Modified Logistic Regression MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_classifier = ModifiedLogisticRegression(max_iter=1000, l_rate=0.001, seed=331)\n",
    "name = \"MLR\"\n",
    "\n",
    "pu_classifier.parameters_update(np.copy(train_x), np.copy(s))\n",
    "pu_classifier.fit(np.copy(train_x), np.copy(s))\n",
    "pu_classifier.estimate_c()\n",
    "\n",
    "pred_y = pu_classifier.predict(np.copy(test_x))\n",
    "pred_prob_y = pu_classifier.predict_proba(np.copy(test_x))\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(test_y, pred_y))\n",
    "print(name,\"MSE score:\", mse(best_prob_y, pred_prob_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e149a2",
   "metadata": {},
   "source": [
    "### 1-DNFII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a765fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation indicates whether two feature values are considered the same\n",
    "# if deviation = 0, the two feature values need to be exactly the same\n",
    "# if deviation = 1, feature value one need to be equal to feature value two - 1\n",
    "#                   OR feature value one need to be equal to feature value two + 1\n",
    "#                   OR the two feature values are exactly the same\n",
    "global deviation \n",
    "deviation = 0.1\n",
    "\n",
    "# the parameter lambda used in 1-DNFII\n",
    "global parameter_lambda \n",
    "parameter_lambda = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34bb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of a certain score for a certain feature\n",
    "def frequency(feature, score, collection):\n",
    "    count = 0\n",
    "    for element in collection:\n",
    "        if (element[feature] > score - deviation) and (element[feature] < score + deviation):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# algorithm improved 1-DNF (1-DNFII)\n",
    "def dnf(train_x, train_y):\n",
    "    num_rows, num_cols = train_x.shape\n",
    "    \n",
    "    # PF = positive feature set\n",
    "    PF = np.zeros(shape=(0, 2))\n",
    "    \n",
    "    # RN = reliable negatives\n",
    "    RN = np.zeros(shape=(0, num_cols))\n",
    "    RN_y = np.array([])\n",
    "    \n",
    "    # U = unlabeled\n",
    "    U = np.zeros(shape=(0, num_cols))\n",
    "    U_y = np.array([])\n",
    "    \n",
    "    # P = positive\n",
    "    P = np.zeros(shape=(0, num_cols))\n",
    "    P_y = np.array([])\n",
    "    \n",
    "    # construct P, U and RN\n",
    "    # at this moment: RN = U\n",
    "    for i in range(0, len(train_y)-1):\n",
    "        if (train_y[i] == 1):\n",
    "            P = np.vstack([P, train_x[i]])\n",
    "            P_y = np.append(P_y, train_y[i])\n",
    "        else:\n",
    "            U = np.vstack([U, train_x[i]])\n",
    "            U_y = np.append(U_y, train_y[i])\n",
    "            RN = np.vstack([RN, train_x[i]])\n",
    "            RN_y = np.append(RN_y, train_y[i])\n",
    "            \n",
    "    print(\"1-DNFII: RN is initialized\")\n",
    "\n",
    "    # construct PF\n",
    "    for i in range(0, num_cols-1):\n",
    "        for j in range(0, num_rows-1):\n",
    "            symbol = train_x[j][i]\n",
    "            if (not [i, symbol] in PF):\n",
    "                constraint_1 = frequency(i, symbol, P) / len(P)\n",
    "                constraint_2 = frequency(i, symbol, U) / len(U)\n",
    "                if (constraint_1 > constraint_2) and (constraint_1 > parameter_lambda):\n",
    "                    new = [i, symbol]\n",
    "                    PF = np.vstack([PF, new])\n",
    "                \n",
    "    print(\"1-DNFII: PF is constructed\")\n",
    "              \n",
    "    # construct list with indices of elements to remove from RN\n",
    "    # (based on PF)\n",
    "    index = []        \n",
    "    for i in range(0, len(RN)-1):\n",
    "        for constraint in PF:\n",
    "            element = RN[i]\n",
    "            if element[int(constraint[0])] == constraint[1]:\n",
    "                index.append(i)\n",
    "              \n",
    "    RN = np.delete(RN, index, 0)\n",
    "    RN_y = np.delete(RN_y, index, 0)\n",
    "                \n",
    "    print(\"1-DNFII: RN was finalized\")\n",
    "    \n",
    "    return P, P_y, U, U_y, RN, RN_y, PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9680a952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-DNFII: RN is initialized\n",
      "1-DNFII: PF is constructed\n",
      "1-DNFII: RN was finalized\n"
     ]
    }
   ],
   "source": [
    "P, P_y, U, U_y, RN, RN_y, PF = dnf(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343ad21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weighted_voting_list(classifiers, weights, listt):\n",
    "    result = []\n",
    "    for elem in listt:\n",
    "        result.append(predict_weighted_voting(classifiers, weights, elem))\n",
    "    return result\n",
    "    \n",
    "def predict_weighted_voting(classifiers, weigths, x):\n",
    "    score = 0\n",
    "    for i in range(0, len(FinalWVClassifier)):\n",
    "        score += FinalWVClassifier_weights[i] * FinalWVClassifier[i].predict(x)\n",
    "    return score\n",
    "\n",
    "def setdiff_nd_positivenums(a,b):\n",
    "    s = np.maximum(a.max(0)+1,b.max(0)+1)\n",
    "    return a[~np.isin(a.dot(s),b.dot(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669db164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(gamma='auto'))])]\n"
     ]
    }
   ],
   "source": [
    "FinalWVClassifier = []\n",
    "FinalWVClassifier_weights = []\n",
    "\n",
    "# shuffle rows of P and then delete the first 10%\n",
    "P = np.insert(P, -1, P_y, axis=1)\n",
    "np.random.shuffle(P)\n",
    "PP = P[:round(len(P)/10),:]\n",
    "PP_y = PP[:, -1]\n",
    "PP = np.delete(PP, -1, 1)\n",
    "index = [x for x in range(0, round(len(P)/10))]\n",
    "P = np.delete(P, index, 0)\n",
    "P_y = P[:, -1]\n",
    "P = np.delete(P, -1, 1)\n",
    "\n",
    "PON = np.vstack([P, RN])\n",
    "PON_y = np.append(P_y, RN_y)\n",
    "\n",
    "RN = np.insert(RN, -1, RN_y, axis=1)\n",
    "\n",
    "U = np.insert(U, -1, U_y, axis=1)\n",
    "U = setdiff_nd_positivenums(U, RN)\n",
    "U_y = U[:, -1]\n",
    "U = np.delete(U, -1, 1)\n",
    "\n",
    "allPrecision = 0\n",
    "\n",
    "while (True):\n",
    "    if (len(U) == 0):\n",
    "        break\n",
    "    \n",
    "    new_clf = make_pipeline(StandardScaler(), svm.SVC(gamma='auto'))\n",
    "    PON_y = np.rint(PON_y)\n",
    "    new_clf.fit(np.copy(PON), np.copy(PON_y))\n",
    "    NEG = new_clf.predict(np.copy(U))\n",
    "    predictions = new_clf.predict(np.copy(PP))\n",
    "    \n",
    "    #TP = ((predictions == 1) & (PP_y == 1)).sum()\n",
    "    #FP = ((predictions == 1) & (PP_y == 0)).sum()\n",
    "    #precision = TP / (TP+FP)\n",
    "    #allPrecision += precision\n",
    "     \n",
    "    index = []\n",
    "    \n",
    "    for i in range(0, len(NEG)):\n",
    "        if (NEG[i] == 0):\n",
    "            index.append(i)\n",
    "            PON = np.vstack([PON, U[i, :]])\n",
    "            PON_y = np.append(PON_y, NEG[i])\n",
    "            \n",
    "    U = np.delete(U, index, 0)\n",
    "    \n",
    "    FinalWVClassifier.append(new_clf)\n",
    "    FinalWVClassifier_weights.append(1)\n",
    "    \n",
    "#for elem in FinalWVClassifier_weights:\n",
    "#    elem = elem / allPrecision\n",
    "    \n",
    "print(FinalWVClassifier_weights)\n",
    "print(FinalWVClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9262b3ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.91836735 0.73076923 0.         0.20183486 0.5        0.\n 0.         0.         0.         0.         0.         0.\n 0.12941176 0.11827957 0.09677419 0.1744186  0.52325581 0.54117647\n 0.30769231 0.63414634 0.38297872 0.3       ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_93035/1870407780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1-DNFII\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_weighted_voting_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinalWVClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFinalWVClassifier_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"F1 score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_93035/1043725084.py\u001b[0m in \u001b[0;36mpredict_weighted_voting_list\u001b[0;34m(classifiers, weights, listt)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_weighted_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_93035/1043725084.py\u001b[0m in \u001b[0;36mpredict_weighted_voting\u001b[0;34m(classifiers, weigths, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinalWVClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mFinalWVClassifier_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFinalWVClassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    762\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.91836735 0.73076923 0.         0.20183486 0.5        0.\n 0.         0.         0.         0.         0.         0.\n 0.12941176 0.11827957 0.09677419 0.1744186  0.52325581 0.54117647\n 0.30769231 0.63414634 0.38297872 0.3       ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "name = \"1-DNFII\"\n",
    "pred_y = predict_weighted_voting_list(FinalWVClassifier, FinalWVClassifier_weights, np.copy(test_x))         \n",
    "print(name,\"F1 score:\", f1_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7fc59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
